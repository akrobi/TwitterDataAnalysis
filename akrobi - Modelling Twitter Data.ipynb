{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74268e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strftime\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "# Building a Sentiment Classifier using Scikit-Learn\n",
    "\n",
    "### Importing required libraries\n",
    "\n",
    "import json\n",
    "from time import strftime\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(json_file,'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "\n",
    "    return len(tweets_data), tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "\n",
    "    # an example function\n",
    "    def find_statuses_count(self)->list:\n",
    "        # the status count of the USER who sent the tweet\n",
    "        statuses_count = []\n",
    "        for tweet in self.tweets_list:\n",
    "            statuses_count.append(tweet['user']['statuses_count'])\n",
    "\n",
    "        return statuses_count\n",
    "        \n",
    "    def find_full_text(self)->list:\n",
    "        text = []\n",
    "        for tweet in self.tweets_list:\n",
    "            text.append(tweet['full_text'])\n",
    "\n",
    "        # text =  self.tweets_list['full_text']\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def find_sentiments(self, text)->list:\n",
    "        polarity=[TextBlob(tweet).sentiment.polarity for  tweet in text] \n",
    "        subjectivity=[TextBlob(tweet).sentiment.subjectivity for tweet in text]\n",
    "        return polarity, subjectivity\n",
    "\n",
    "    def find_created_time(self)->list:\n",
    "        #converts the time from a string to an integer\n",
    "        created_at = []\n",
    "        for tweet in self.tweets_list:\n",
    "            created_at.append((tweet['created_at']))\n",
    "\n",
    "        return created_at\n",
    "    \n",
    "    def find_source(self)->list:\n",
    "        source = []\n",
    "        for i in self.tweets_list:\n",
    "            source.append(i['source'])\n",
    "        return source\n",
    "    \n",
    "    def is_sensitive(self)->list:\n",
    "            is_sensitive = []\n",
    "\n",
    "            for tweet in self.tweets_list:\n",
    "                if 'possibly_sensitive' in tweet.keys():\n",
    "                    is_sensitive.append(tweet['possibly_sensitive'])\n",
    "                else:\n",
    "                    is_sensitive.append(None)\n",
    "            return is_sensitive\n",
    "def find_location(self)->list:\n",
    "        location = []\n",
    "\n",
    "        for tweet in self.tweets_list:\n",
    "            if 'location' in tweet['user'].keys():\n",
    "                location.append(tweet['user']['location'])\n",
    "            else:\n",
    "                location.append(None) \n",
    "        # try:\n",
    "        #     location.append([self.tweets_list['user']['location']])\n",
    "        # except TypeError:\n",
    "        #     location = ''\n",
    "        \n",
    "        return location\n",
    "\n",
    "           \n",
    "    def get_tweet_df(self, save=False)->pd.DataFrame:\n",
    "        #required column to be generated you should be creative and add more features\n",
    "        \n",
    "        # columns = ['created_at', 'source', 'original_text','polarity','subjectivity', 'lang', \n",
    "        #             'favorite_count', 'retweet_count', 'original_author', 'followers_count',\n",
    "        #             'friends_count','possibly_sensitive', 'hashtags', 'user_mentions', 'place']\n",
    "        columns = ['created_at', 'source', 'original_text', 'polarity', 'subjectivity', \n",
    "                    'sensitivity', 'location']\n",
    "        \n",
    "        created_at = self.find_created_time()\n",
    "        source = self.find_source()\n",
    "        text = self.find_full_text()\n",
    "        polarity, subjectivity = self.find_sentiments(text)\n",
    "        # lang = self.find_lang()\n",
    "        # fav_count = self.find_favourite_count()\n",
    "        # retweet_count = self.find_retweet_count()\n",
    "        # screen_name = self.find_screen_name()\n",
    "        # follower_count = self.find_followers_count()\n",
    "        # friends_count = self.find_friends_count()\n",
    "        sensitivity = self.is_sensitive()\n",
    "        # hashtags = self.find_hashtags()\n",
    "        # mentions = self.find_mentions()\n",
    "        location = self.find_location()\n",
    "        data = zip(created_at, source, text, polarity, subjectivity,sensitivity, location) \n",
    "                    # text, polarity, subjectivity, lang, fav_count, \n",
    "                    # retweet_count, screen_name, follower_count, friends_count, sensitivity, \n",
    "                    # hashtags, mentions, location)\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        mysampledf = df.head(10)\n",
    "\n",
    "        if save:\n",
    "            df.to_csv('processed_tweet_data.csv', index=False)\n",
    "            mysampledf.to_json('data/sample.json')\n",
    "            print('Files Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    # required column to be generated you should be creative and add more features\n",
    "    columns = ['created_at', 'source', 'original_text','clean_text', 'sentiment','polarity',\n",
    "                'subjectivity', 'lang', 'favorite_count', 'retweet_count', 'original_author', \n",
    "                'screen_count', 'followers_count','friends_count','possibly_sensitive', 'hashtags', \n",
    "                'user_mentions', 'place', 'place_coord_boundaries']\n",
    "    _, tweet_list = read_json(\"Desktop/TwitterDataAnalysis/data/global_twitter_data.json\")\n",
    "\n",
    "\n",
    "    tweet = TweetDfExtractor(tweet_list)\n",
    "    tweet_df = tweet.get_tweet_df() \n",
    "    print(tweet_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd18eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e9f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd08c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
